<!DOCTYPE html>
<html lang="en-AU">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>MESS Analytics &#8211; Mathematics, Spatial and Statistic and in Economics.</title>

    <!-- favicon -->
    <link rel="apple-touch-icon" sizes="180x180" href="../../../llib/img/logo/apple-touch-icon.png">
    <link rel="icon" type="image/`png" sizes="32x32" href="../../../llib/img/logo/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../../llib/img/logo/favicon-16x16.png">
    <link rel="manifest" href="../../../llib/img/logo/site.webmanifest">


    <link rel='stylesheet' id='bootstrap-css' href='../../../lib/third-party/bootstrap.min.css?ver=4.8.9' type='text/css' media='all' />
    <link rel='stylesheet' id='meanmenu-css' href='../../../lib/third-party/meanmenu.css?ver=4.8.9' type='text/css' media='all' />
    <link rel='stylesheet' id='font-awesome-css' href='../../../lib/font-awesome/css/font-awesome.min.css?ver=4.8.9' type='text/css' media='all' />
    <link rel='stylesheet' id='blog-way-fonts-css' href='../../../lib/css/latin.css' type='text/css' media='all' />
    <link rel='stylesheet' id='blog-way-style-css' href='../../../lib/css/style.css?ver=4.8.9' type='text/css' media='all' />

    <style>
        body {
            color: #404040;
        }
        
        .site-title a {
            color: #222222;
        }
        
        .site-description {
            color: #818181;
        }
        
        h1,
        h2,
        h3,
        h4,
        h5,
        h6,
        .entry-header h2.entry-title a {
            color: #404040;
        }
        
        #primary .cat-links a {
            color: #ea9920;
        }
        
        .content-area a {
            color: #ea9920;
        }
        
        header#masthead {
            background: #202020;
        }
        
        .main-navigation ul li a {
            color: #ffffff;
        }
        
        #masthead .main-navigation li.current-menu-item a,
        .main-navigation ul.menu li:hover a {
            color: #afafaf;
        }
        
        .widget .widget-title {
            background: #ffffff;
        }
        
        .site-footer,
        .footer-social .menu-social-menu-container #menu-social-menu {
            background: #202020;
        }
        
        .site-info,
        .site-info a {
            color: #787878;
        }
        
        button,
        input[type="button"],
        input[type="reset"],
        input[type="submit"],
        .nav-links .nav-previous a,
        .nav-links .nav-next a,
        .nav-links .page-numbers,
        .pagination .page-numbers.next,
        .pagination .page-numbers.previous {
            border: 1px solid #202020;
            background: #202020;
        }
        
        .scrollup {
            background-color: #ea9920;
        }
    </style>

    <style type="text/css">
        .recentcomments a {
            display: inline !important;
            padding: 0 !important;
            margin: 0 !important;
        }
    </style>
    <!--<link rel="stylesheet" href="styles.css">-->
    <!-- take this out for no triangulation-->
</head>

<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>

<body class="home blog hfeed sticky-top">
    <div id="page" class="site">
        <header id="masthead" class="site-header navbar-fixed-top" role="banner">
            <div class="container">
                <div class="row">
                    <div class="col-sm-12">
                        <nav id="site-navigation" class="main-navigation" role="navigation">
                            <div class="menu-catergories-container">
                                <ul id="primary-menu" class="menu">
                                    <li id="menu-item-51" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-51"><a href="../../../index.html">Home</a></li>
                                    <li id="menu-item-53" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-53"><a href="../../../research.html">Research</a></li>
                                    <li id="menu-item-54" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-54"><a href="../../../services.html">Services</a></li>
                                    <li id="menu-item-50" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-50"><a href="../../../downloads.html">Downloads</a></li>
                                    <li id="menu-item-50" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-50"><a href="../../../contacts.html">Contact</a></li>
                                    <li id="menu-item-50" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-50"><a href="../../../personal.html">Personal</a></li>
                                    <li id="menu-item-50" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-50"><a href="../../../posts.html">Posts</a></li>
                                </ul>
                            </div>
                        </nav>
                    </div>
                </div>
                <!-- .row -->
            </div>
            <!-- .container -->
        </header>
        <!-- #masthead -->
        <div class="main-banner banner-disabled">
            <div class="container">
                <div class="row">

                    <div class="site-branding">

                        <h1 class="site-title"><a href="../../../posts.html" rel="home">MESS Analytics</a></h1>

                        <p class="site-description">Blog on Mathematics, Economics, Spatial and Statistic </p>
                    </div>
                    <!-- .site-branding -->
                </div>
            </div>
        </div>
        <!-- .main-banner -->
        <div id="content" class="site-content">
            <div class="container">
                <div class="row">
                    <div class="col-md-8 col-sm-12 layout-right-sidebar">
                        <div id="primary" class="content-area">
                            <main id="main" class="site-main" role="main">

                                <article id="post-42" class="post-42 post type-post status-publish format-standard has-post-thumbnail hentry category-mathematics category-statistics tag-linear-regression tag-statistics">
                                    <div class="detail-wrap">
                                        <header class="entry-header">
                                            <span class="cat-links"> <a href="" rel="category tag">Statistics</a></span>
                                            <h1 class="entry-title">Fitting Linear Regression Models</h1> </header>
                                        <!-- .entry-header -->

                                        <div class="entry-content">
                                        

                                        <p>For any given datasets there are usually a range of possible regression models. Model selection is dependent on included variables and transformations.
                                        This article presents criteria useful in selecting the 'best' model and hopes to provide a systematical approach. </p>

                                        <p>Usual assumptions of normality and independence are not always guaranteed. The methods described checks for
                                           validity of these models assumptions prior to drawing insights from model. Suppose we have linear regression in a general form.</p>
                                        $$ { Y  = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_k x_k} +\epsilon $$
                                        
                                        <p> and we make n independent observations, y1,y2,y3 â€¦ yn, on Y. We can write as yi observations as,</p>
                                        $$ { y_i  = \beta_0 + \beta_1 {x_i}_1 + \beta_2 {x_i}_2 + ... + \beta_k {x_i}_k} +\epsilon_i $$

                                        <p>where xij is the set of the jith independent variable for th ith observation, i = 1,2,.., n. Defined as matrix, with x0 =1.</p>
                                        $$ \left[\begin{matrix}  y_1  \\  y_2  \\ \vdots  \\ y_n \end{matrix} \right] = 
                                        \left[\begin{matrix}  1 & {x_1}_1 & ... & {x_1}_k  \\  1 & {x_2}_1 & ... & {x_2}_k \\ \vdots & \vdots &   \ddots  &   \vdots \\ 1 & {x_n}_1 & ... & {x_n}_k \end{matrix} \right]
                                        
                                        \left[\begin{matrix}  \beta_1   \\  \beta_2  \\ \vdots \\ \beta_k \end{matrix} \right]  + 
                                        
                                        \left[\begin{matrix}  \epsilon_1   \\  \epsilon_2  \\ \vdots  \\ \epsilon_n \end{matrix} \right] $$
                                        <p>Given these definitions we will proceed to model selection, before solving matrix with least-square estimation in Part 2. </p>

                        <!-- .$$ { B_0 = \frac{ \sum y- ( \beta_1 *  \sums x)} { n }} $$ -->

                                        </br><p><strong>Model Selection and Checking</strong></p>
                                            <p>To determine the &#8216;best&#8217; regression equation from a multiple regression model that involves k regressors, X1,X2,X3 &#8230; Xk, there exist contradictory criteria.</p>
                                            <ul>
                                                <li>We should include as many regressors as possible to be useful.</li>
                                                <li>We should exclude as many regressors to save cost in collecting data.</li>
                                            </ul>
                                            <p><strong>SELECTING CRITERIA</strong></p>
                                            <p>Selecting the <em>bestÂ </em>regression model (essential regressors) is reasonable compromise between the above two extremes. Here are five popular criteria for assessing theÂ <em>best </em>model.</p>
                                            <ol>
                                                <li style="text-align: left;"><strong>Coefficients of multiple determination (R^2).</strong> &#8211; Maximise
                                                    $$ { R^2  = \frac{ \hat Y' \hat Y - n \bar Y^2 } { Y'Y - n \bar Y^2 }  = \frac{ SSRegression}{SSTotal} } $$

                                                    $$ { = 1 - \frac{ (Y - \hat Y)' ( Y- \hat Y)} { Y'Y - n \bar Y^2 }  = 1 - \frac{ SSError}{SSTotal} } $$
                                                    <!-- <img src="R2-e1508916070303-300x95.png" />-->
                                                    <p> The proportion of Y (about Y hat) explained by the regressors in the model is defined byÂ <em>coefficients of multiple determination, R^2.Â </em>
                                                    <br /> If the SSRegression becomes larger or the SSError decreases the R^2 increase.
                                                    <br /> By including additional independent variables (regressors) increases R^2, even if coefficient maybe not too different from zero. So maximizing the number of variables included in model may also maximize R^2. We should therefore be careful in selecting model based on larger R^2.
                                                    <br />
                                                    <em><em><p><span style="color: #808080;">* To safeguard we can penalize inclusion of new variables unless they make </span>significant<span style="color: #808080;"> contribution, adjusted coefficient of multiple determination. n -1 is total degrees of freedom, n-p is residual degrees of freedom for model ith.</span></em></em>
                                                    </p></li><br />
                                                <li><strong>Mean square residual</strong>. &#8211; Minimise <!--  <img src="R2-1-e1508917793128-300x49.png" /> -->
                                                    
                                                    $$ { MSE_i = 1 - \frac{SSE_i} { n-p}} $$
                                                    <p>where (n-p) is the residual for Model. 
                                                    The most appropriate model is the smallest MSE value or the lowest unexplained variation per degree of freedom. The equivalence of MSE to R^2 shown as,</p></li>
                                                    $$ { \bar R^2_i  = 1 - \frac{SSError_i/(n-p)} { SSTotal/(n-1) } = 1 - \frac{n-1} { n-p } (1- R^2_i)} $$
                                                    
                                                    <li><strong>Cm statistic</strong>.Â  &#8211; Minimise</li>

                                                    $$ { C_m  =  \frac{SSE_i} {s^2} - (n-2m) } $$
                                                     <p>Similar To MSE, Cm  tries to minimise the unexplained variance, though the square residuals and number of regressors *m and s^2 the mean square residual.
                                                     Cm is closely related to R. The proportion of variation explaied by the regression 

                                                <li><strong>PRESS statistic</strong> &#8211; Minimise
                                                    $$ { PRESS_i  = \sum_{j=1}^n (y_j+ \hat y_j )^2  = \sum_{j=0}^n (  \frac{e_j} {1- {h_j}_j} )^2 } $$
                                                    <p>Prediction Error of Sum Squares (PRESS), future responses (predicted) are used to estimate the mean response.
                                                    <br /> Steps
                                                    <br /> &#8211; Set regressors in given model and compute the prediction of each variable.
                                                    <br /> &#8211; Omit observationÂ <em>j</em>, from the data and refit model to this reduce dataset.
                                                    <br /> &#8211; Predict missing observation with refitted model.
                                                    <br /> &#8211; Repeat steps above fore each variable of model.
                                                    <br />
                                                    <br />
                                                    
                                                    <!--   <img src="PRESS-e1508922085982-300x79.png" /></li>--> 

                                                <li><strong>AIC.</strong> &#8211; Minimise
                                                    $$ { AIC  = -2 log-likelihood + 2p } $$
                                                    <p>Akaike&#8217;s Information Criterion. Understands that fitting more and more covariates can only reduce the residual sum of squares and Mean Square Error thus increasing R^2. 
                                                        AIC uses a penalty term to discourage the introduction of unnecessary covariates.</p>
                                                    <!-- <img src="R23-2-e1508922159508-300x86.png" sizes="(max-width: 348px) 100vw, 348px" /></li>--> 
                                            </ol>
                                            <b><strong>PROCEDURE</strong></b>
                                            <p>The following are standard procedures in choosing the &#8216;best&#8217; model.</p>
                                            <ol>
                                                <li>All possible regressions. The process of fitting all the equation using the combination of regressors and then selecting the &#8216;best&#8217; model based on the previous criteria approach can be very time consuming and requires large computing power.</li>
                                                <br /><li>Backward elimination. Starting with all regressors and then choosingÂ a good model by eliminating regressor variables with no or small effect on response. Using the previous statistics criteria, however partial F-statistic or AIC is recommended.</li>
                                                <br /><li>Forward selection. Starting with only the intercept term fitted in the model. Like the backward elimination use of F-Statistic or AIC as the regressors are added to check contribution. The regressor variable with the highest simple correlation and F-value that is greater than Falpha enters the model first.</li>
                                                <br /><li>Stepwise regression. Similar to forward selection, the procedure to starts with just intercept fitted. However, at each step all regressors entered into the model are reassessed by using a backward elimination approach.</li>
                                            </ol>

                                            <p>Moving on from model selection, we will investigate model adequacy with residual analysis, diagnostic checksÂ and Multi-collinearity</p>
                                            <p><strong>Model Adequacy</strong></p>
                                            <p>In determining a linear model the usual assumption in the specification are not always guaranteed. For least squares the estimation of parameters as well as prediction depend on the validity of theses assumption. Therefore, it is critical to check if any assumptions that are violated and apply the necessary measures if needed.</p>
                                            <p>The checks on these adequacy of models assumptions are based on the analysis of these residuals. When the model is correctly fitted the residuals should confirm the assumptions and not show contradictions.</p>
                                            
                                            
                                             
                                            <ol>
                                            <li style="text-align: left;"><strong>Residual Analysis</strong></li>

                                            \[ 
                                            \text{$e_j  =y_j -   \hat{j} $, where $j = 1,2, ...,n$} 
                                            \]

                                            <p>Measuring the extent of departure from th regression assumptions, we will use it to detect
                                                any violation in assumption. A measure of variability is </p>
                                                $$ { \frac {\sum_{j=1}^n (e_j - \hat e )^2} {n - p} = 
                                                    \frac {\sum_{j=1}^n e_j^2} {n - p} =  
                                                    \frac {SS3} {n - p}
                                                     = MSE = s^2, } $$
                                                     
                                            <p>unbiased least-square estimate of the error variance,</p>$$  Var[e = \sigma^2]$$
                                            <p>working with scaled residuals, may convey more information than ordinary, shown as.</p>
                                            $$ { d_j  =\frac {e_j} {\sqrt {MSE}} = \frac {e_j} {s} }$$
                                            
                                            <p> for j = 1,2,..,n.</s>

                                            <li style="text-align: left;"><strong>Diagnostic Checks</strong></li>
                                            </br><p>In addition to the residual analysis to verify the model assumptions, here are some further
                                            graphical and numerical diagnostic methods are useful in the understanding
                                            of the sample data.</p>

                                            $$ {C_l = \frac {q^2_l } {p} \left ( \frac {{h_l}_l} {1-{h_l}_l} \right )  } $$
                                            <p>Cook's distance, is based on the change in estimated regression coefficients due to the exclusion of 
                                                an influential observation from analysis. 
                                            </p>


                                            $$ { DEFITS  =\frac {\hat y_l - { \hat y_-l}_l} {\hat {\sigma_(}_l \sqrt { {h_l}_l}}  }$$
                                            <p>DEFITS, is the difference in the fitted value standardised</p>

                                            <li style="text-align: left;"><strong>Multicollinearity</strong></li>
                                            </br><p>Aside from error distributions and residuals, there are other types of problems
                                                associated with fitting a regression model. Such as Multicollinearity.
                                            </p>
                                            <p>Multicollinearity occurs when there is a linear or near-linear relationship between two or more regressors, 
                                               identification of Multicollinearity methods can be described with the following methods.</p>
                                            <p> Correlation matrix provide sample correlation coefficients of the regressors, these coefficients
                                                show the strength of the linear relationship between the pairs of regressors.
                                                A general adopted rule is that if a correlation coefficients is greater than 0.8 in absolute value then
                                                there is a strong linear association which is indicative of presence of multicollinearity. Therefore, one
                                                may simply check the of-diagonal elements of the correlation matrix to detect multicollinearity.</p>
                                            
                                            <p>The characteristic roots of (X'X) matrix can be used to measure the
                                                extent of multicollinearity in a given data set. The presence of one
                                                or more small characteristic roots indicates one or more linear dependencies among the regressors. 
                                                The condition number of (X'X), defined as: </p>

                                                $$ {\Psi = 	\frac{\lambda^*} {\lambda_* }   }$$

                                            <p>where, lambda 1 and lambda 2 are the largest and smallest characteristic roots of
                                                (X'X). Usually, if characteristic roots  < 100, the problem of multicollinearity is not
                                                serious and if 100 <= characteristic roots < 1000, the problem is moderate to strong.
                                                When characteristic roots > 1000 then there is an acute problem of multicollinearity.
                                            </p>

                                            <p>Possible solutions could be to include additional data or respecication of model.
                                                Collection of more data, with appropriate sampling design for use in analysis so 
                                                that the effect of multicollinearity is removed.
                                                Respecication, for avoiding redundant variables reduces the chance of collinear effect
                                                and the affects of multicollinearity. Identifying if regressors are nearly linearly independent
                                                is possible with some functions as follow,
                                            </p>

                                            $$ { X^*_1 =X_1, X_2, X_3  \text{ or }  X_2 = \frac{X_1 + X_2} { X_3 } } $$

                                            <p><b>Conclusion</b></p> 
                                            <p> In this post we have shown, selection a 'best' model is not easy given nature is complicated.
                                                Showing that the regressors that determine a model are potentially many and how assumptions
                                                with models are often unrealistic. Verification of regression are critical and methods for selecting
                                                regressors for a 'best' model. Sound inference on model is made when model is carefully selected and its 
                                                assumptions are duly met. 
                                            </p>
                                            <!-- pg 93 studybook, statistical models -->   

                                        </ol>
                                            
                     
                                        
                                        
                                        
                                        </div>
                                        <!-- .entry-content -->
                                    </div>
                                </article>

                            </main>
                            <!-- #main -->
                        </div>
                        <!-- #primary -->
                    </div>
                                <div class="col-md-4 col-sm-12">
                                    <aside id="secondary" class="widget-area" role="complementary">
            
                                        <section id="search-2" class="widget widget_search">
                                            <form role="search" method="get" class="search-form" action="">
                                                <label>
                                                    <span class="screen-reader-text">Search for:</span>
                                                    <input type="search" class="search-field" placeholder="Search &hellip;" value="" name="s" />
                                                </label>
                                                <input type="submit" class="search-submit" value="Search" />
                                            </form>
                                        </section>
                                        <section id="recent-posts-2" class="widget widget_recent_entries">
                                            <h2 class="widget-title">Recent Posts</h2>
                                            <ul>
                                                <li>
                                                    <a href="../10/fitting_linear_regression_models_part2.html">Fitting Linear Regression Part 2</a>
                                                </li>
                                                <li>
                                                    <a href="">Fitting Linear Regression Models</a>
                                                </li>
            
                                            </ul>
                                        </section>
                                        <section id="recent-comments-2" class="widget widget_recent_comments">
                                            <h2 class="widget-title">Recent Comments</h2>
                                            <ul id="recentcomments">
                                                <li class="recentcomments"><span class="comment-author-link"><a href='' rel='external nofollow' class='url'>geometry dash</a></span> on <a href="/first-post/#comment-2">First Post</a></li>
                                            </ul>
                                        </section>
                                        <section id="archives-2" class="widget widget_archive">
                                            <h2 class="widget-title">Archives</h2>
                                            <ul>
                                                <li><a href='../10/fitting_linear_regression_models_part2.html'>October 2017</a></li>
                                                <li><a href='../07/fitting_linear_regression_models.html'>July 2017</a></li>
                                            </ul>
                                        </section>
                                        <section id="categories-2" class="widget widget_categories">
                                            <h2 class="widget-title">Categories</h2>
                                            <ul>
                                                <li class="cat-item cat-item-4"><a href="">Economics</a>
                                                </li>
                                                <li class="cat-item cat-item-3"><a href="">Mathematics</a>
                                                </li>
                                                <li class="cat-item cat-item-5"><a href="">Spatial</a>
                                                </li>
                                                <li class="cat-item cat-item-2"><a href="">Statistics</a>
                                                </li>
                                            </ul>
                                        </section>
            
                                    </aside>
                                    <!-- #secondary -->
                                </div>                            





                                <!-- #post-## -->
                                <nav class="navigation post-navigation" role="navigation">
                                    <h2 class="screen-reader-text">Post navigation</h2>
                                    <div class="nav-links">
                                        <div class="nav-next"><a href="../10/fitting_linear_regression_models_part2.html" rel="next">Fitting Linear Regression Part 2</a></div>
                                    </div>
                                </nav>

                            </main>
                            <!-- #main -->
                        </div>
                        <!-- #primary -->
                    </div>
                    <!-- .col-md-8 -->
                    

                </div>
                <!-- .row -->
            </div>
            <!-- .container -->
        </div>
        <!-- #content -->
        <footer id="colophon" class="site-footer" role="contentinfo">
            <div class="site-info">
                <div class="container">
                </div>
                <!-- .container -->
            </div>
            <!-- .site-info -->
        </footer>
        <!-- #colophon -->

    </div>
    <!-- #page -->

    <a href="#page" class="scrollup" id="btn-scrollup"><i class="fa fa-angle-up"></i></a>

</body>

</html>